{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在pytorch框架下的数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "lr = 0.001              # learning rate\n",
    "download_mnist = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判断本地当前目录有无MNIST_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists('./mnist_data/')) or not os.listdir('./mnist_data/'):\n",
    "    DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换 PIL.Image or numpy.ndarray 成torch.FloatTensor (C  H  W), 训练的时候 normalize 成 [0.0, 1.0] 区间\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist_data/',    # 保存或者提取位置\n",
    "    train=True,         # 训练数据\n",
    "    transform=torchvision.transforms.ToTensor(),    # 转换 PIL.Image or numpy.ndarray 成\n",
    "                                                    # torch.FloatTensor (C  H  W), 训练的时候 normalize 成 [0.0, 1.0] 区间\n",
    "    download=download_mnist,          # 没下载就下载, 下载了就不用再下了\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./mnist_data/\n",
      "    Split: Train\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.train_data.size())                 \n",
    "print(train_data.train_labels.size())    \n",
    "print(train_data)\n",
    "print(train_data[1][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示训练集中第4张图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.train_data[3].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "test_data = torchvision.datasets.MNIST(root='./mnist_data/', train=False)\n",
    "\n",
    "# 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(type(train_loader))\n",
    "\n",
    "# 为了节约时间, 我们测试时只测试前2000个\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=16,    # n_filters\n",
    "                kernel_size=5,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=2,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "            ),      # output shape (16, 28, 28)\n",
    "            nn.ReLU(),    # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(  # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32, 14, 14)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.MaxPool2d(2),  # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打印网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=lr) #optimizer 所有cnn参数\n",
    "loss_func = nn.CrossEntropyLoss()     #损失函数（类似于TensorFlow中的交叉熵tf.nn.softmax_cross_entropy_with_logits）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.2824 | test accuracy: 0.18\n",
      "Epoch:  0 | train loss: 0.5541 | test accuracy: 0.82\n",
      "Epoch:  0 | train loss: 0.1413 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.2657 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.0794 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1813 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.0670 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0978 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0809 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0672 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1638 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1204 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0397 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1374 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1588 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0238 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1994 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0357 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0338 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0215 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0070 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0388 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0436 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0149 | test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader): \n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "        optimizer.zero_grad()            \n",
    "        loss.backward()                 \n",
    "        optimizer.step()  \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  张量tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[1., 2., 3.],\n",
      "         [1., 2., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[[1,2,3],[1,2,4]]]).type(torch.FloatTensor)\n",
    "y = torch.Tensor([[[1,2,3],[1,2,4]]]).type(torch.float32)\n",
    "print(x.size())\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存网络模型 |  提取网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, './net.pkl')\n",
    "net = torch.load('./net.pkl')\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试十张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "test_output = net(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
